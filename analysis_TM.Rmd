---
title: "Data_Analisis_Scopus_WoS"
author: "Sebastian Robledo"
date: "1/28/2022"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Creating the environment

```{r, echo=FALSE}
library(tidyverse)
library(tidygraph)
library(igraph)
library(bibliometrix)
library(tosr)
library(here)
library(lubridate)
library(sjrdata)
library(openxlsx)
library(zoo)
```

# Getting data

```{r}
wos <- bibliometrix::convert2df(here("data", 
                                     "savedrecs_TM.txt"), 
                                "wos", 
                                format = "plaintext")

scopus <- bibliometrix::convert2df(here("data",
                                        "scopus_TM.bib"), 
                                   dbsource = "scopus", 
                                   format = "bibtex")

wos_scopus_tos <- tosr_load("data/savedrecs_TM.txt", "data/scopus_TM.bib")

```

# Data tidying

We will merge Scopus and WoS

```{r}
wos_scopus_unique <- 
  scopus |> 
  select(SR) |> 
  bind_rows(wos |> 
              select(SR)) |> 
  unique() # There are 2042 unique registers
```

We add scopus and wos dataset

```{r}
wos_scopus_unique_scopus <- 
  wos_scopus_unique |> 
  left_join(scopus |> 
              mutate(database = "scopus"), 
            by = "SR") 

wos_scopus_unique_wos <- 
  wos_scopus_unique_scopus |>
  filter(is.na(database)) |> 
  select(SR) |> 
  left_join(wos |> 
              mutate(database = "wos"), 
            by = "SR")
```

Unifying tags in scopus and wos

```{r}
wos_titles <- tibble(title = names(wos_scopus_unique_wos))
scopus_titles <- tibble(title = names(wos_scopus_unique_scopus))

unique_scopus_wos_titles <- inner_join(scopus_titles, wos_titles)
```

Selecting only unique tags in both datasets

```{r}
scopus_unique_titles <- 
  wos_scopus_unique_scopus |> 
  filter(!is.na(database)) |> 
  select(unique_scopus_wos_titles |> 
           pull())

wos_unique_titles <- 
  wos_scopus_unique_wos |> 
  select(unique_scopus_wos_titles |> 
           pull())
```

Merging both datasets scopus and wos

```{r}
scopus_wos_final <- 
  scopus_unique_titles |> 
  bind_rows(wos_unique_titles) # 2042 registers!!!!!
```

# Data analysis

```{r}
wos_anual_production <- 
  wos |> 
  select(PY) |> 
  count(PY, sort = TRUE) |> 
  na.omit() |> 
  filter(PY >= 2000,
         PY < year(today())) |> 
  mutate(ref_type = "wos") |> 
  bind_rows(tibble(PY = c(2004, 
                          2005, 
                          2006, 
                          2007, 
                          2008),
                   n = 0, 
                   ref_type = "wos"))

scopus_anual_production  <- 
  scopus |> 
  select(PY) |> 
  count(PY, sort = TRUE) |> 
  na.omit() |> 
  filter(PY >= 2000,
         PY < year(today())) |>
  mutate(ref_type = "scopus") |> 
  bind_rows(tibble(PY = 2007, n = 0, ref_type = "scopus"))

total_anual_production <- 
  wos_scopus_tos$df |> 
  select(PY) |> 
  count(PY, sort = TRUE) |> 
  na.omit() |> 
  filter(PY >= 2000,
         PY < year(today())) |>
  mutate(ref_type = "total") |> 
  bind_rows(tibble(PY = 2007, 
                   n = 0, 
                   ref_type = "total")) |> 
  arrange(desc(PY))

wos_scopus_total_annual_production <- 
  wos_anual_production |> 
  bind_rows(scopus_anual_production,
            total_anual_production) 

# Checking results of total

wos_scopus_total_annual_production_dummy <- 
  total_anual_production |> 
  rename(n_total = n,
         ref_type_total = ref_type) |> 
  left_join(wos_anual_production |> 
              rename(n_wos = n,
              ref_type_wos = ref_type) ) |> 
  left_join(scopus_anual_production |> 
              rename(n_scopus = n,
              ref_type_scopus = ref_type)) |> 
  mutate(total = if_else(n_total < n_wos | n_total < n_scopus, 
                         n_scopus, # it could be improved
                         n_total))

wos_scopus_total_annual_production_total <- 
  wos_scopus_total_annual_production_dummy |> 
  select(PY, 
         n = total,
         ref_type = ref_type_total)

wos_scopus_total_annual_production_scopus <- 
  wos_scopus_total_annual_production_dummy |> 
  select(PY, 
         n = n_scopus,
         ref_type = ref_type_scopus)

wos_scopus_total_annual_production_wos <- 
  wos_scopus_total_annual_production_dummy |> 
  select(PY, 
         n = n_wos,
         ref_type = ref_type_wos)

wos_scopus_total_annual_production <- 
  wos_scopus_total_annual_production_total |> 
  bind_rows(wos_scopus_total_annual_production_scopus,
            wos_scopus_total_annual_production_wos) 

figure_1_data <-
  wos_scopus_total_annual_production |>
  mutate(PY = replace_na(PY, replace = 0)) |>
  pivot_wider(names_from = ref_type,
              values_from = n) |>
  arrange(desc(PY))

wos_scopus_total_annual_production |>
  ggplot(aes(x = PY, y = n, color = ref_type)) +
  geom_line() +
  labs(title = "Annual Scientific Production",
       x = "years",
       y = "papers") +
  theme(plot.title = element_text(hjust = 0.5))
```

I would like to create a bar graph of WoS and Scopus data

We need to identify the times cited variable for each database and later sum them all.

Time Cited from web of science

```{r}
TC_wos <- 
  wos |> 
  select(PY, TC) |> 
  group_by(PY) |> 
  summarise(TC_sum = sum(TC)) |> 
  arrange(desc(PY)) |> 
  na.omit() |> 
  bind_rows(tibble(PY = c(2004, 
                          2005, 
                          2006, 
                          2007, 
                          2008),
                   TC_sum = 0))
```

Time Cited from WoS

```{r}
TC_scopus <- 
  scopus |> 
  select(PY, TC) |> 
  group_by(PY) |> 
  summarise(TC_sum = sum(TC)) |> 
  arrange(desc(PY)) |> 
  na.omit() |> 
  bind_rows(tibble(PY = 2007, TC_sum = 0))
```

Time cited all

```{r}
TC_all <- 
  TC_scopus |> 
  left_join(TC_wos, 
            by = "PY", 
            suffix = c("_wos", 
                       "_scopus")) |> 
  replace_na(replace = list(TC_sum_scopus = 0)) |> 
  mutate(TC_sum_all = TC_sum_wos + TC_sum_scopus,
         TC_total = sum(TC_sum_all),
         TC_percentage = round(TC_sum_all/TC_total, digits = 2)) |> 
  select(PY, TC_sum_all, TC_percentage) |> 
  filter(PY != 2022) |> 
  arrange(desc(PY))
```

# 3.1.1 Scientific Production

## Figure 1a

```{r}
figure_1a <- 
  wos_scopus_total_annual_production |> 
  filter(ref_type != "total") |> 
  ggplot(aes(x = factor(PY), 
             y = n, 
             fill = ref_type)) +
  geom_bar(stat = "identity", 
           position = "dodge") +
  geom_text(aes(label = n),
            vjust = -0.3,
            position = position_dodge(0.9),
            size = 3,
            family = "Times") +
  scale_fill_manual(values = c("springgreen3",
                               "orange3")) +
  theme(text = element_text(family = "Times",
                            face = "bold",
                            size =12),
        panel.background = element_rect(fill = "white"),
        legend.position = "bottom",
        legend.title = element_text(size = 0),
        axis.text.x = element_text(face = "bold", 
                                   angle = 45, 
                                   vjust = 0.5),
        axis.line = element_line(color = "black", 
                                 size = 0.2)) +
  labs(y = "Number of publications", 
       x = "Year") +
  scale_y_continuous(breaks = seq(0,300, 
                                  by = 50)) 
figure_1a

```

## Figure 1b

```{r}

figure_1b <- 
  wos_scopus_total_annual_production_dummy |> 
  ggplot(aes(x = PY, y = total)) +
  geom_line(stat = "identity", color = "red") +
  geom_point(stat = "identity", color = "red") +
  scale_x_continuous(breaks = seq(2004, 2021, by = 1)) +
  geom_text(aes(label = total),
            vjust = -0.3,
            position = position_dodge(0.9),
            size = 3,
            family = "Times", 
            color = "red") +
  scale_fill_manual(values = c("springgreen3",
                               "orange3")) +
  theme(text = element_text(family = "Times",
                            face = "bold",
                            size =12),
        panel.background = element_rect(fill = "white"),
        legend.position = "bottom",
        legend.title = element_text(size = 0),
        axis.text.x = element_text(face = "bold", 
                                   angle = 45, 
                                   vjust = 0.5),
        axis.line = element_line(color = "black", 
                                 size = 0.2)) +
  labs(y = "Number of total publications", 
       x = "Year") +
  scale_y_continuous(breaks = seq(0,300, 
                                  by = 50)) +
  geom_bar(stat = "identity",
           aes(y = n_total)) +
  geom_line(aes(y = total)) +
  scale_y_continuous(
    name = "First Axis",
    sec.axis = sec_axis(~., name = "Second Axis"), 
  )

figure_1b

```

## Figure 1b_1

```{r}
wos_scopus_total_annual_production_dummy |> 
  ggplot(aes(x = PY)) +
  geom_bar(stat = "identity",
           aes(y = n_total)) +
  geom_line(aes(y = total)) +
  scale_y_continuous(
    name = "First Axis",
    sec.axis = sec_axis(~., name = "Second Axis"), 
  )
```

## Figure 1c

```{r}
figure_1c <- 
  TC_all |> 
  ggplot(aes(x = PY , y = TC_sum_all)) +
  geom_line(stat = "identity", color = "purple") +
  geom_point(color = "purple") +
  scale_x_continuous(breaks = seq(2004, 2021, by = 1)) +
  geom_text(aes(label = TC_sum_all),
            vjust = -0.3,
            position = position_dodge(0.9),
            size = 3,
            family = "Times", 
            color = "purple") +
  scale_fill_manual(values = c("springgreen3",
                               "orange3")) +
  theme(text = element_text(family = "Times",
                            face = "bold",
                            size =12),
        panel.background = element_rect(fill = "white"),
        legend.position = "bottom",
        legend.title = element_text(size = 0),
        axis.text.x = element_text(face = "bold", 
                                   angle = 45, 
                                   vjust = 0.5),
        axis.line = element_line(color = "black", 
                                 size = 0.2)) +
  labs(y = "Number of citations", 
       x = "Year") +
  scale_y_continuous(breaks = seq(0,3500, 
                                  by = 500)) 

figure_1c
```

## Figure 1 - Final

Final Figure 1 with inkscape

![](figures/Figure_1_a.svg)

### Total publications

Total papers in the whole time

```{r}
total_publications <- 
  wos_scopus_total_annual_production |> 
  filter(ref_type %in% c("wos", "scopus")) |> 
  select(n) |> 
  summarize(total = sum(n)) |> 
  pull()

total_publications
```

### Total Citations

```{r}
TC_all_pull <- 
  TC_all |>
  summarize(ig_total_citaitons = sum(TC_sum_all)) |> 
  pull()

TC_all_pull
```

### Initial Growth Stage

Total papers in the initial growth stage

```{r}
ig_stage_publications <- 
  wos_scopus_total_annual_production |> 
  filter(PY >= 2004, 
         PY <= 2013, 
         ref_type %in% c("wos", "scopus")) |> 
  select(n) |> 
  summarize(total = sum(n))

ig_stage_publications |> pull()
```

Therefore, the proportion of papers in the initial stage compare with the sum of all stages is **10.54%** (227/2154\*100)

Total papers for WoS in the initial growth stage

```{r}
ig_stage_publications_wos <- 
  wos_scopus_total_annual_production |> 
  filter(PY >= 2004, 
         PY <= 2013, 
         ref_type %in% c("wos", "scopus")) |> 
  filter(ref_type == "wos") |>
  select(n) |> 
  summarize(total = sum(n))

ig_stage_publications_wos |> pull()
```

Total papers for Scopus in the initial growth stage

```{r}
ig_stage_publications_scopus <- 
  wos_scopus_total_annual_production |> 
  filter(PY >= 2004, 
         PY <= 2013, 
         ref_type %in% c("wos", "scopus")) |> 
  filter(ref_type == "scopus") |>
  select(n) |> 
  summarize(total = sum(n))

ig_stage_publications_scopus |> pull()
```

Total citations in initial growth stage

```{r}
TC_ig <- 
  TC_all |> 
  filter(PY >= 2004, 
         PY <= 2013) |> 
  summarize(ig_total_citaitons = sum(TC_sum_all)) |> 
  pull()

TC_ig
```

```{r}

TC_ig/TC_all_pull*100
```

What is the most cited paper during IG stage?

```{r}
wos_scopus_tos$df |> 
  select(TI, TC, PY) |> 
  filter(PY >=2004,
         PY <= 2013) |> 
  arrange(desc(TC)) |> View()

```

### Rapid Development Stage

Total papers in the rd stage

```{r}
rd_stage_publications <- 
  wos_scopus_total_annual_production |> 
  filter(PY >= 2014, 
         PY <= 2019, 
         ref_type %in% c("wos", "scopus")) |> 
  select(n) |> 
  summarize(total = sum(n)) |> 
  pull()

rd_stage_publications

```

Percentage of the total publications

```{r}
rd_stage_publications / total_publications *100
```

Total citations in the rd stage

```{r}
TC_rd <- 
  TC_all |> 
  filter(PY >= 2014, 
         PY <= 2019) |> 
  summarize(ig_total_citaitons = sum(TC_sum_all)) |> 
  pull()

TC_rd
```

Percentage of the total citations

```{r}
TC_rd / TC_all_pull *100
```

Calculating the average growth percentage of publications during rd stage

```{r}
rd_publications_growth_rate <- 
  wos_scopus_tos$df %>%
  filter(PY >= 2014,
         PY <= 2019) |> 
  select(PY) |> 
  count(PY) |> 
  # first sort by year
  arrange(PY) %>%
  mutate(diff_growth = n - lag(n),
         rate_percentage = (diff_growth/n)*100,
         rate_percentage = round(rate_percentage, 
                                 digits = 2) )

mean(rd_publications_growth_rate |> 
       select(rate_percentage) |> 
       pull(), 
     na.rm = TRUE)
```

Finding the most cited document during this stage

```{r}
wos_scopus_tos$df |> 
  filter(PY == 2016) |>
  select(TI, PY, TC) |> 
  arrange(desc(TC)) |> 
  slice(1) |> 
  select(TI) |> 
  pull()
```

Which is the most productive journal in rd stage

```{r}
wos_scopus_tos$df |> 
  filter(PY >= 2014,
         PY <= 2019) |>
  select(SO, TC) |>
  filter(TC > 0) |>
  group_by(SO) |> 
  summarise(sum_citations = sum(TC),
            count = n()) |> View()
```

### Stability Stage

```{r}
stability_stage_publications <- 
  wos_scopus_total_annual_production |> 
  filter(PY >= 2020, 
         PY <= 2021, 
         ref_type %in% c("wos", "scopus")) |> 
  select(n) |> 
  summarize(total = sum(n)) |> 
  pull()

stability_stage_publications
  
```

Percentage

```{r}
stability_stage_publications / total_publications * 100
```

Growth rate

```{r}
stability_publications_growth_rate <- 
  wos_scopus_tos$df %>%
  filter(PY >= 2020,
         PY <= 2021) |> 
  select(PY) |> 
  count(PY) |> 
  # first sort by year
  arrange(PY) %>%
  mutate(diff_growth = n - lag(n),
         rate_percentage = (diff_growth/n)*100,
         rate_percentage = round(rate_percentage, 
                                 digits = 2) )

mean(stability_publications_growth_rate |> 
       select(rate_percentage) |> 
       pull(), 
     na.rm = TRUE)
```

# 3.1.2 Country analysis

## Table 2 - Country production

```{r}
wos_scopus_countries <- 
  wos_scopus_tos$df |> 
  select(SR, AU_CO, TC) |> 
  separate_rows(AU_CO, sep = ";") |> 
  unique() |> 
  drop_na()

wos_scopus_countries_journals <- 
  wos_scopus_countries |> 
  left_join(wos_scopus_tos$df |> 
              select(SR, SO, PY), 
            by = "SR")

scimago_2020 <- 
  read_csv2("data/scimago2020.csv") |> 
  select(SO = Title,
         quartile = "SJR Best Quartile") |> 
  mutate(PY = 2020)

scimago_2021 <- 
  read_csv2("data/scimago2020.csv") |> 
  select(SO = Title,
         quartile = "SJR Best Quartile") |> 
  mutate(PY = 2021)

scimago <- 
  sjr_journals |> 
  select(PY = year, 
         SO = title,
         quartile = sjr_best_quartile) |> 
  mutate(SO = str_to_upper(SO),
         PY = as.numeric(PY)) |> 
  bind_rows(scimago_2020_2021)

scimago_2020_2021 <- 
  scimago_2020 |> 
  bind_rows(scimago_2021) |> 
  select(PY, SO, quartile)

wos_scopus_countries_journals_scimago <- 
  wos_scopus_countries_journals |> 
  left_join(scimago, by = c("PY", "SO")) |>  
  drop_na() |> 
  select(AU_CO, TC, quartile) |> 
  filter(quartile != "-")


```

### Table 2a - production

Production per country

```{r}
table_2a <- 
  wos_scopus_countries |> 
  select(AU_CO) |> 
  group_by(AU_CO) |> 
  summarise(count_co = n()) |> 
  mutate(percentage_co = count_co / sum(count_co) * 100,
         percentage_co = round(percentage_co, digits = 2)) |> 
  arrange(desc(count_co))

table_2a 
```

Total percentage of the top 10 Countries

```{r}
table_2a |> 
  slice(1:10) |> 
  select(percentage_co) |> 
  summarise(total_sum_per = sum(percentage_co)) |> 
  pull()
```

### Table 2b - citations

Citations received per country

```{r}
table_2b <- 
  wos_scopus_countries_journals_scimago |> 
  select(AU_CO, TC) |> 
  group_by(AU_CO) |> 
  summarise(citation = sum(TC)) |> 
  mutate(percentage_ci = citation / sum(citation) * 100) |> 
  arrange(desc(citation))

table_2b
```

Total percentage of citation of the top 10 countries

```{r}
table_2b |> 
  slice(1:10) |> 
  select(percentage_ci) |> 
  summarise(total_sum_per = sum(percentage_ci)) |> 
  pull()
```

### Table 2c - Quartiles

```{r}
table_2c <- 
  wos_scopus_countries_journals_scimago |> 
  select(AU_CO, quartile) |> 
  group_by(AU_CO) |> 
  count(quartile, sort = TRUE) |> 
  pivot_wider(names_from = quartile, 
              values_from = n) |> 
  select(AU_CO, Q1, Q2, Q3, Q4) |> 
  mutate(Q1 = replace_na(Q1, 0),
         Q2 = replace_na(Q2, 0),
         Q3 = replace_na(Q3, 0),
         Q4 = replace_na(Q4, 0))


table_2c
```

### Table 2 - Final

Merging all tables 2

```{r}
table_2 <- 
  table_2a |> 
  left_join(table_2b, by = "AU_CO") |> 
  left_join(table_2c, by = "AU_CO") |> 
  slice(1:10)

table_2
```

## Figure 2 - Country Collaboration

Exporting data to biblioshiny

```{r}
write.xlsx(x = wos_scopus_tos$df, file = "output/wos_scopus.xlsx")
```

# Academic Social Network

## Scopus

We need to extract the edgelist from scopus and their references

```{r}
asn_scopus_1 <- 
  scopus_wos_final |> 
  filter(database == "scopus") |> 
  mutate(ID_TOS = str_extract(SR, ".*,"))

asn_scopus_ref <- 
  asn_scopus_1 |> 
  select(CR) |> 
  separate_rows(CR, sep = "; ") |> 
  mutate(lastname = sub("\\., .*", "", CR),
         lastname = sub(",", "", lastname),
         lastname = sub("\\.", "", lastname),
         year = str_extract(CR, "\\(([0-9]{4})\\)"),
         year = str_remove_all(year, "\\(|\\)")) |> 
    mutate(lastname = str_replace(lastname, 
                                pattern = "\\.", 
                                replacement = ""),
         ID_TOS = paste0(lastname, ", ", year, ",")) |> 
  select(ID_TOS, CR)

edgelist_scopus_ref_dummy <- 
  tibble(Source = as.character(),
         Target = as.character(),
         year = as.character())
for (i in 1:length(asn_scopus_ref$CR)) {
  
  df_1 <- 
    asn_scopus_ref |> 
    select(CR) |> 
    slice(i) |>
    mutate(year_2 = str_extract(CR, "\\([0-9]{4}\\)"),
           year_1 = str_remove(year_2, "\\("),
           year = str_remove(year_1, "\\)"),
           authors_2 = str_remove(CR, 
                                  "\\([0-9]{4}\\) .*"),
           authors_1 = str_extract(authors_2,
                                   ".*\\.,"),
           authors = str_replace_all(authors_1,
                                     "\\.", 
                                     replacement = "")) |> 
    select(authors, year) |> 
    separate_rows(authors, sep = ", ") |> 
    mutate(authors = str_replace(authors, ",", ""))
    
  df_2 <- 
    df_1 |> 
    select(authors) |> 
    pull() |> 
    zoo::rollapply(2, by=2, c) |> 
    as_tibble() |> 
    unite(authors, sep = " ") |> 
    mutate(authors = str_replace(authors, "(?<= [[:alpha:]]).*", ""))
  
  if (dim(df_2)[1] >= 2) {
    
    df_3 <- 
      df_2 |> 
      pull() |> 
      combn(2, simplify = FALSE) |> 
      as_tibble(.name_repair = "minimal") |> 
      t() |> 
      data.frame() |> 
      dplyr::rename(Source = 1, 
                    Target = 2)
    
    df_4 <- 
      df_3 |> 
      bind_cols(df_1 |> 
                  select(year) |> 
                  unique())
    
    edgelist_scopus_ref_dummy <- 
      edgelist_scopus_ref_dummy |> 
      bind_rows(df_4) 
    
  }
}

edgelist_scopus_ref <- edgelist_scopus_ref_dummy |> 
  filter(!str_detect(Source, "[0-9]"),
         !str_detect(Target, "[0-9]")) |> 
  mutate(year = as.numeric(year))
```

Edge list of main papers

```{r}
data_tidied_scopus_main <- 
  scopus_wos_final |> 
  filter(database %in% "scopus") |> 
  select(SR, AU, PY) |> 
  separate_rows(AU, sep = ";")

edgelist_scopus_dummy <- 
  tibble(Source = as.character(),
         Target = as.character(),
         year = as.numeric())

for (i in data_tidied_scopus_main$SR) {
  
  df_1 <- data_tidied_scopus_main |> 
    filter(SR %in% i) |> 
    dplyr::rename(year = PY)
  
  if (dim(df_1)[1] >= 2) {
    
    df_2 <- df_1 |> 
      select(AU) |> 
      pull() |> 
      combn(2, simplify = FALSE) |> 
      as_tibble(.name_repair = "minimal") |> 
      t() |> 
      data.frame() |> 
      dplyr::rename(Source = 1, 
                    Target = 2)
    
    df_3 <- 
      df_2 |> 
      bind_cols(df_1 |> 
                  select(year) |> 
                  unique())
    
    edgelist_scopus_dummy <- 
      edgelist_scopus_dummy |> 
      bind_rows(df_3)
    
  }
  
}
```

Merging both edge lists

```{r}
edgelist_total_scopus <- 
  edgelist_scopus_dummy |>
  bind_rows(edgelist_scopus_ref) |> 
  mutate(Source  = str_trim(Source, side = "both"),
         Target = str_trim(Target, side = "both")) |> 
  na.omit()
edgelist_total_scopus |> dplyr::count(Source, Target, year)
```

Creating the graph

```{r}

author_cocitation_network_scopus <- 
  edgelist_total_scopus |> 
  add_count(Source, Target, year) |> 
  graph.data.frame(directed = FALSE) |> 
  simplify()
author_cocitation_network_scopus |> 
  summary()
```

## WoS

### 1. Selecting dois from refs

```{r}
DOI <- 
  data_tidied |> 
  filter(database %in% "wos") |> 
  select(CR) |> 
  separate_rows(CR, sep = ";") |> # 1650 rows
  filter(str_detect(CR, "DOI"))  |>   # 1300 rows
  mutate(DOI = str_remove(CR, ".*DOI ")) |> 
  distinct(DOI)    # 8248 rows
```

### 2. Getting authors from dois ref

```{r}
##########################################################################
#### Extracci?n de la informaci?n de los art?culos de las referencias ####
##########################################################################
references <- data.frame(DI = character(), 
                         PU = character(), 
                         SO = character(), 
                         J9 = character(), 
                         PD = character(), 
                         PY = character(), 
                         TI = character(), 
                         AF = character(), 
                         stringsAsFactors = FALSE)
authors <- data.frame(doi = character(), 
                      author = character(), 
                      year = character(), 
                      month = character(), 
                      stringsAsFactors = FALSE)
for (i in DOI$DOI) {
  doi <- i
  url <- paste0("http://api.crossref.org/works/", doi, ".xml")
  xml_data_1 = try(xmlParse(url), silent = TRUE);
  if (class(xml_data_1) == "try-error") {
    next
  } else  {
    xml_data_2 <- xmlToList(xml_data_1)
    
    notfound =try(as.list(xml_data_2[["query_result"]][["body"]][["query"]][["doi"]][[".attrs"]]) == "journal_article", silent = TRUE);
    if (class(notfound) == "try-error"){
      next
    }else{
      
      if (as.list(xml_data_2[["query_result"]][["body"]][["query"]][["doi"]][[".attrs"]]) == "journal_article"){
        
        # PUBLISHER-NAME
        
        
        if (is.null(xml_data_2[["query_result"]][["body"]][["query"]][["crm-item"]])){
          PU <- as.character(NA) 
        } else {
          
          publisher0 <- as.list(xml_data_2[["query_result"]][["body"]][["query"]][["crm-item"]])
          publisher <- data.frame(publisher0)
          if(nrow(publisher) == 0){
            PU <- as.character(NA)
          }else{
            PU <- as.character(publisher$text[1])
          }
        }
        
        # JOURNAL FULL TITLE 
        
        
        if (is.null(xml_data_2[["query_result"]][["body"]][["query"]][["doi_record"]][["crossref"]][["journal"]][["journal_metadata"]][["full_title"]])){
          SO <- as.character(NA) 
        } else {
          
          journal0 <- as.list(xml_data_2[["query_result"]][["body"]][["query"]][["doi_record"]][["crossref"]][["journal"]][["journal_metadata"]][["full_title"]])
          journal <- data.frame(journal0)
          if(nrow(journal) == 0){
            SO <- as.character(NA)
          }else{
            SO <- as.character(journal[1,1])
          }
        }
        
        # JOURNAL ABBREV TITLE 
        
        
        if (is.null(xml_data_2[["query_result"]][["body"]][["query"]][["doi_record"]][["crossref"]][["journal"]][["journal_metadata"]][["abbrev_title"]])){
          J9 <- as.character(NA) 
        } else {
          
          journal0 <- as.list(xml_data_2[["query_result"]][["body"]][["query"]][["doi_record"]][["crossref"]][["journal"]][["journal_metadata"]][["abbrev_title"]])
          journal <- data.frame(journal0)
          if(nrow(journal) == 0){
            J9 <- as.character(NA)
          }else{
            J9 <- as.character(journal[1,1])
          }
        }
        
        # MONTH
        
        
        if (is.null(xml_data_2[["query_result"]][["body"]][["query"]][["doi_record"]][["crossref"]][["journal"]][["journal_issue"]][["publication_date"]][["month"]])){
          PD <- as.character(NA) 
        } else {
          
          month0 <- as.list(xml_data_2[["query_result"]][["body"]][["query"]][["doi_record"]][["crossref"]][["journal"]][["journal_issue"]][["publication_date"]][["month"]])
          month <- data.frame(month0)
          if(nrow(month) == 0){
            PD <- as.character(NA)
          }else{
            PD <- as.character(month[1,1]) 
          }
        }
        
        # YEAR
        
        
        if (is.null(xml_data_2[["query_result"]][["body"]][["query"]][["doi_record"]][["crossref"]][["journal"]][["journal_issue"]][["publication_date"]][["year"]])){
          PY <- as.character(NA) 
        } else {
          
          Year0 <- as.list(xml_data_2[["query_result"]][["body"]][["query"]][["doi_record"]][["crossref"]][["journal"]][["journal_issue"]][["publication_date"]][["year"]])
          Year <- data.frame(Year0)
          if(nrow(Year) == 0){
            PY <- as.character(NA)
          }else{
            PY <- as.character(Year[1,1]) 
          }
        }
        
        # TITLE
        
        
        if (is.null(xml_data_2[["query_result"]][["body"]][["query"]][["doi_record"]][["crossref"]][["journal"]][["journal_article"]][["titles"]][["title"]])){
          TI <- as.character(NA) 
        } else {
          
          title0 <- as.list(xml_data_2[["query_result"]][["body"]][["query"]][["doi_record"]][["crossref"]][["journal"]][["journal_article"]][["titles"]][["title"]])
          title <- try(data.frame(title0), silent = TRUE);
          
          if(class(title) == "try-error"){
            titlex <- try(ldply(title0, data.frame), silent = TRUE);
            if(class(titlex) == "try-error"){
              TI <- as.character(NA)
            }else{
              TI0 <- as.character(titlex[1,2])
              TI <- trimws(TI0)
            }
          }else{
            if(nrow(title) == 0){
              TI <- as.character(NA)
            }else{
              TI <- as.character(title[1,1])
            }
          }
        }
        
        # CONTRIBUTORS
        
        
        if (is.null(xml_data_2[["query_result"]][["body"]][["query"]][["doi_record"]][["crossref"]][["journal"]][["journal_article"]][["contributors"]]))
        {
          AF <- as.character(NA)
        } else {
          
          author_ref <- as.list(xml_data_2[["query_result"]][["body"]][["query"]][["doi_record"]][["crossref"]][["journal"]][["journal_article"]][["contributors"]])
          
          author_1_ref <- ldply(author_ref, data.frame)
          author_2_ref <- author_1_ref[author_1_ref$.attrs == "author", c(2,3) ]
          
          authorss <- data.frame(doi= doi, author = paste0(author_2_ref$surname, ", ", author_2_ref$given_name), year = PY, month = PD)
          
          authors = rbind(authors, authorss)
          authorss$author <- trim(authorss$author)
          AF <- as.character(paste(authorss$author, collapse = ";   "))
        }
        
        references0 <- data.frame(DI = doi, PU = PU, SO = SO, J9 = J9, PD = PD, PY = PY, TI = TI, AF = AF)
        references = rbind(references, references0) 
        
      }else {
        next}
    }
  }
} 
authors$month <- sub("^[0]+", "", authors$month) # Elimina los ceros a la izquierda en los meses
```

### 3. Getting authors from main wos

```{r}
##########################################################################
#### Separaci?n de los nombres de los autores de los art?culos de WoS ####
##########################################################################
wos_author <- # 1339 - 3
  data_tidied |> 
  filter(database %in% "wos") |>
  select(doi = DI, AU, PY) |> 
  separate_rows(AU, sep = ";") |> 
  dplyr::rename(author = AU)
```

### 4. Merging main with refs dois with names

```{r}
#################################################################
#### Uni?n de los datos de WoS y de las referencias de estos ####
#################################################################
authors$author <- gsub("(?<=, [[:alpha:]]).*", "", authors$author, perl=TRUE)
wos_author_ref <- # 27051 3 doi author year 
  authors |> 
  mutate(author = str_replace(author, ",", "")) |> 
  select(doi, author, year) |> 
  mutate(author = str_to_upper(author))
```

### 5. Getting edge list from (4)

We need to remove dois with only one author

```{r}
dois_one_author <- 
  wos_author_ref |> 
  count(doi) |> 
  filter(n == 1) |> # 970 total
  select(doi)
```

We need to identify dois with high number of co-authors

```{r}
dois_high_author <- 
  wos_author_ref |> 
  count(doi, sort = TRUE) |> 
  slice(1:9) |> 
  select(doi)
```

We need to merge these two dataframes

```{r}
dois_to_remove <- 
  dois_one_author |> 
  bind_rows(dois_high_author)
```

We need to remove the dois from wos_author_ref

```{r}
wos_author_removed <- 
  wos_author_ref |> 
  filter(!(doi %in% dois_to_remove$doi))
```

```{r}
###########################
#### Listas de enlaces ####
###########################
# # Para art?culos que tienen como m?nimo dos autores
# author_1 <- # 4273 3 there a mistake with the duplicate values. 
#   wos_author |> # 190
#   filter(!is.na(PY)) |> 
#   dplyr::rename(year = PY,
#                 doi = DI) |> 
#   bind_rows(wos_author_ref |> 
#               mutate(year = as.numeric(year))) |> # 4104
#   unique() |> 
#   filter(!(doi %in% "10.3109/13880209.2014.922589" & 
#          year == 2014)) # this is a duplicate value with != year

edgelist_wos_authors <- data.frame(Source = character(), 
                                   Target = character(), 
                                   doi = character(),
                                   year = as.numeric(),
                                   stringsAsFactors = FALSE)

# table_ids <- table(author_1$doi)
# table_ids_0 <- data.frame(table_ids)
# table_ids_1 <- table_ids_0[table_ids_0$Freq >= 2,]
list_ids_1 <- unique(wos_author_removed$doi)

for (i in list_ids_1) {
  df_1 = wos_author_removed[wos_author_removed$doi == i,] |> 
    filter(!is.na(doi))
  df_2 = combn(df_1$author, 2, simplify = FALSE)
  df_3 = data.frame((t(data.frame(df_2))), i)
  colnames(df_3) = c("Source", "Target", "doi")
  df_4 <- df_3 |> bind_cols(df_1 |> select(year) |> unique())
  edgelist_wos_authors = rbind(edgelist_wos_authors, df_4)
}
```

### 6. Creating the graph object

```{r}
asn_wos <- 
  graph.data.frame(edgelist_wos_authors, 
                   directed = FALSE) |> 
  simplify() |> 
  as_tbl_graph()

```

## WoS and Scopus graph

Merging both datasets

```{r}
edgelist_scopus_wos <- 
  edgelist_total_scopus |> 
  bind_rows(edgelist_wos_authors |> 
             select(Source, Target, year))  # We can not remove duplicates

edgelist_scopus_wos_no_years <- 
  edgelist_total_scopus |> 
  select(-year) |> 
  count(Source, Target) |> 
  select(Source, Target)
```

Creating the ASN - graph object

```{r}
asn_TM <-
  edgelist_scopus_wos |>
  graph.data.frame(directed = FALSE) |> 
  as_tbl_graph()

asn_TM_no_years <- 
  edgelist_scopus_wos_no_years |> 
  graph.data.frame(directed = FALSE) |> 
  simplify() |> 
  as_tbl_graph()
  
```

## ASN stats

Filtering the connected graph and some stats - degree and louvain

```{r}
asn_TM_connected <- 
  asn_TM_no_years |> 
  activate(nodes) |> 
  mutate(components = group_components(type = "weak")) |> 
  filter(components == 1) |> 
  mutate(degree = centrality_degree(),
         community = as.factor(group_louvain()))
```

Analyzing the size of each community

```{r}
asn_TM_connected |> 
  activate(nodes) |> 
  data.frame() |> 
  count(community) |>
  slice(1:20) |>  
  ggplot(aes(x = reorder(community, n), y = n)) +
  geom_point(stat = "identity") +
  geom_line(group = 1) + 
  # geom_text(label = community,
  #           nudge_x = 0.5,
  #           nudge_y = 0.5,
  #           check_overlap = T) +
  labs(title = "Communities by size", 
       x = "communities", 
       y = "Authors") +
  theme(text = element_text(color = "black",
                            face = "bold",
                            family = "Times New Roman"),
        plot.title = element_text(size = 25),
        panel.background = element_rect(fill = "white"), 
        axis.text.y = element_text(size = 15, 
                                   colour = "black"),
        axis.text.x = element_text(size = 15,
                                   colour = "black"),
        axis.title.x = element_text(size = 20),
        axis.title.y = element_text(size = 20)) 
```

Filtering only the top 10 nodes with best degree in the first 6 clusters.

```{r}
asn_TM_connected_1 <- 
  asn_TM_connected |> 
  activate(nodes) |>
  mutate(community = as.numeric(community)) |> 
  # filter(community >= 6) |> 
  filter(community == 1) |> 
  # group_by(community) |> 
  mutate(degree_community = centrality_degree()) |> 
  arrange(desc(degree_community)) |> 
  slice(1:20)

asn_TM_connected_2 <- 
  asn_TM_connected |> 
  activate(nodes) |>
  mutate(community = as.numeric(community)) |> 
  # filter(community >= 6) |> 
  filter(community == 2) |> 
  # group_by(community) |> 
  mutate(degree_community = centrality_degree()) |> 
  arrange(desc(degree_community)) |> 
  slice(1:20)

asn_TM_connected_3 <- 
  asn_TM_connected |> 
  activate(nodes) |>
  mutate(community = as.numeric(community)) |> 
  # filter(community >= 6) |> 
  filter(community == 3) |> 
  # group_by(community) |> 
  mutate(degree_community = centrality_degree()) |> 
  arrange(desc(degree_community)) |> 
  slice(1:20)

asn_TM_connected_4 <- 
  asn_TM_connected |> 
  activate(nodes) |>
  mutate(community = as.numeric(community)) |> 
  # filter(community >= 6) |> 
  filter(community == 4) |> 
  # group_by(community) |> 
  mutate(degree_community = centrality_degree()) |> 
  arrange(desc(degree_community)) |> 
  slice(1:20)

asn_TM_connected_5 <- 
  asn_TM_connected |> 
  activate(nodes) |>
  mutate(community = as.numeric(community)) |> 
  # filter(community >= 6) |> 
  filter(community == 5) |> 
  # group_by(community) |> 
  mutate(degree_community = centrality_degree()) |> 
  arrange(desc(degree_community)) |> 
  slice(1:20)

asn_TM_connected_6 <- 
  asn_TM_connected |> 
  activate(nodes) |>
  mutate(community = as.numeric(community)) |> 
  # filter(community >= 6) |> 
  filter(community == 6) |> 
  # group_by(community) |> 
  mutate(degree_community = centrality_degree()) |> 
  arrange(desc(degree_community)) |> 
  slice(1:20)

```

Saving the nodes we're gonna show

```{r}
nodes_community_1 <- 
  asn_TM_connected_1 |> 
  activate(nodes) |> 
  as_tibble() |> 
  select(name)

nodes_community_2 <- 
  asn_TM_connected_2 |> 
  activate(nodes) |> 
  as_tibble() |> 
  select(name)

nodes_community_3 <- 
  asn_TM_connected_3 |> 
  activate(nodes) |> 
  as_tibble() |> 
  select(name)

nodes_community_4 <- 
  asn_TM_connected_4 |> 
  activate(nodes) |> 
  as_tibble() |> 
  select(name)

nodes_community_5 <- 
  asn_TM_connected_5 |> 
  activate(nodes) |> 
  as_tibble() |> 
  select(name)

nodes_community_6 <- 
  asn_TM_connected_6 |> 
  activate(nodes) |> 
  as_tibble() |> 
  select(name)

nodes_selected_20 <- 
  nodes_community_1 |> 
  bind_rows(nodes_community_2, 
            nodes_community_3,
            nodes_community_4,
            nodes_community_5,
            nodes_community_6)

```

Filtering selected nodes

```{r}
asn_TM_selected_nodes <- 
  asn_TM_connected |> 
  activate(nodes) |> 
  filter(name %in% nodes_selected_20$name) |> 
  mutate(final_plot = tidygraph::group_components(type = "weak")) |> 
  filter(final_plot == 1)
```

Ploting the selected network

```{r}
asn_TM_selected_nodes |> 
  ggraph() +
  geom_edge_link() +
  geom_node_point()
```

Exporting graph

```{r}
asn_nodes <- 
  asn_TM_connected |> 
  activate(nodes) |> 
  as_tibble() |>
  rename(author = name) |>
  rownames_to_column("name")

asn_edges <- 
  asn_TM_connected |> 
  activate(edges) |> 
  as_tibble() |> 
  unique()

asn_igraph <- 
  graph_from_data_frame(d = asn_edges, 
                        directed = FALSE, 
                        vertices = asn_nodes)

asn_igraph |> write_graph("output/asn_igraph.graphml", "graphml")
  
```

The graph is super big! We'll

Creating the weighted network of academic social network

```{r}
# we need to remove duplicates with dois. 
edgelist_author_cocitation_wos_scopus <- 
  edgelist_wos_authors |> 
  select(-doi, -year) |> 
  bind_rows(edgelist_total_scopus |> 
              select(-year)) |> 
  add_count(Source, Target) |> 
  unique() |> 
  dplyr::rename(weight = n)

giant.component <- function(graph) {
  cl <- igraph::clusters(graph)
  igraph::induced.subgraph(graph, 
                           which(cl$membership == which.max(cl$csize)))
}

author_cocitation_byproducts <- 
  graph.data.frame(asn_wos_scopus_csv, 
                   directed = FALSE) |> 
  simplify() |> 
  giant.component()  
  
clusters_author_network <- 
  author_cocitation_byproducts |> 
  as.undirected(mode = "each") |> 
  cluster_louvain()

author_cocitation_byproducts_clusters <-
  author_cocitation_byproducts |> 
  set_vertex_attr(name = "cluster",
                  value = membership(clusters_author_network))
  
author_cocitation_byproducts_clusters |> summary()

asn_graph_tbl <- 
  author_cocitation_byproducts_clusters |> 
  as_tbl_graph()
```

Cluster analysis

```{r}
asn_graph_tbl |> 
  activate(node) |> 
  count(cluster) |> 
  ggplot(aes(x = n))
```

Creating the academic social network with year

```{r}
# we need to remove duplicates with dois or scale data...
edgelist_author_cocitation_wos_scopus_year <- 
  edgelist_wos_authors |> 
  select(-doi) |> 
  bind_rows(edgelist_total_scopus) |> 
  unique() |> 
  dplyr::filter(!(is.na(year)))
links_table <- # 21 rows
  edgelist_author_cocitation_wos_scopus_year |> 
  dplyr::count(year, sort = TRUE) |> 
  dplyr::arrange(desc(year)) |> 
  filter(year >= 2000) |> 
  dplyr::mutate(percentage = n/max(n))  |> 
  select(year, percentage)
  
# Create a data frame with author and year 
  
nodes_table <- # 21 row 
  edgelist_author_cocitation_wos_scopus_year |> 
  select(author = Source, year) |>
  bind_rows(edgelist_author_cocitation_wos_scopus_year |> 
              select(author = Target, year)) |> 
  unique() |> 
  group_by(author) |> 
  slice(which.min(year)) |>
  ungroup() |> 
  select(year) |> 
  group_by(year) |> 
  count(year) |> 
  filter(year >= 2000) |> 
  ungroup() |> 
  dplyr::mutate(percentage = n / max(n)) |> 
  select(year, percentage)
```

### ASN nodes and links

```{r}
# Creating the graph with two datasets 
nodes_table |> 
  mutate(type = "nodes") |> 
  bind_rows(links_table |> 
              mutate(type = "links")) |> 
  ggplot(aes(x = year, 
             y = percentage, 
             color = type)) +
  geom_point() +
  geom_line() +
  theme(legend.position = "right", 
        text = element_text(color = "black", 
                            face = "bold",
                            family = "Times New Roman"),
        plot.title = element_text(size = 25),
        panel.background = element_rect(fill = "white"), 
        axis.text.y = element_text(size = 15, 
                                   colour = "black"),
        axis.text.x = element_text(size = 15,
                                   colour = "black"),
        axis.title.x = element_text(size = 20),
        axis.title.y = element_text(size = 20),
        legend.text = element_text(size = "15"), 
        legend.title = element_blank()) +
  labs(title = "Nodes and links through time", 
       y = "") +
  scale_y_continuous(labels = scales::percent) 
```

```{r}
author_cocitation_byproducts <- 
  graph.data.frame(edgelist_author_cocitation_wos_scopus, 
                   directed = FALSE) |> 
  simplify() |> 
  giant.component() 
  
clusters_author_network <- 
  author_cocitation_byproducts |> 
  as.undirected(mode = "each") |> 
  cluster_louvain()
author_cocitation_byproducts_clusters <-
  author_cocitation_byproducts |> 
  set_vertex_attr(name = "cluster",
                  value = membership(clusters_author_network))
  
author_cocitation_byproducts |> summary()
```

reorder(cluster, count)

### ASN clustering graph

```{r}
# byproduct_san_clusters <- 
  tibble(id = V(author_cocitation_byproducts_clusters)$name,
         cluster = V(author_cocitation_byproducts_clusters)$cluster) |>
  select(cluster) |> 
  add_count(cluster) |> 
  unique() |> 
  arrange(desc(n)) |>
  dplyr::rename(count = n) |> 
  filter(count >= 80) |> 
  mutate(clusters = length(cluster):1) |> 
  arrange(desc(clusters)) |> 
  ggplot(aes(x = clusters, y = count)) +
  geom_point() +
  geom_line() +
  geom_text(label = count,
            nudge_x = 0.5,
            nudge_y = 0.5,
            check_overlap = T) +
  labs(title = "Clusters by size", 
       x = "clusters", 
       y = "Authors") +
  theme(text = element_text(color = "black",
                            face = "bold",
                            family = "Times New Roman"),
        plot.title = element_text(size = 25),
        panel.background = element_rect(fill = "white"), 
        axis.text.y = element_text(size = 15, 
                                   colour = "black"),
        axis.text.x = element_text(size = 15,
                                   colour = "black"),
        axis.title.x = element_text(size = 20),
        axis.title.y = element_text(size = 20)) 
  
```

Academic Social Network from Scopus and WoS

```{r}
asn_wos_scopus_csv <-
  read_csv("output/asn_wos_scopus.csv")

asn_graph <- 
  asn_wos_scopus_csv |> 
  graph_from_data_frame(directed = FALSE) 
```

# Others

```{r}
dummy <- 
  edgelist_scopus_ref_dummy |> 
  filter(!str_detect(Source, "[0-9]"),
         !str_detect(Target, "[0-9]")) |> 
  mutate(year = as.numeric(year))

dummy_tbl_graph <- 
  dummy |> 
  graph_from_data_frame(directed = FALSE ) |> 
  tidygraph::as_tbl_graph() |> 
  activate(nodes) |> 
  mutate(degree = centrality_degree())


dummy_tbl_graph |> 
  activate(nodes) |> 
  data.frame() |> View()
  arrange(desc(degree)) |> 
  slice(1:10)

david_blei_1 <- 
  dummy_tbl_graph |> 
  activate(edges) |> 
  data.frame() |> 
  filter(from == 14) |> 
  select(year)

david_blei_2 <- 
  dummy_tbl_graph |> 
  activate(edges) |> 
  data.frame() |> 
  filter(to == 14) |> 
  select(year)

david_blei_1 <- 
  edgelist_scopus_ref_dummy |> 
  filter(Target == "BLEI D") |> 
  select(year)

david_blei_2 <- 
  edgelist_scopus_ref_dummy |> 
  filter(Source == "BLEI D") |> 
  select(year)

david_blei <- 
  david_blei_1 |> 
  bind_rows(david_blei_2) |> 
  count(year, sort = TRUE) |> 
  na.omit()

david_blei |> 
  ggplot(aes(x = year, y = n)) +
  geom_line(aes(group = 1)) + 
  geom_point()
  
```
